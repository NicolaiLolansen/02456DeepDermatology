{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model: Pre-trained Inception V3 - SpatialTransformer\n",
    "\n",
    "#### This notebooks trains the Localization Network which outputs an affine transformation matrix. It uses the pre-trained weights of the Inception V3 trained on the training data fra Aarhus University. The final layer of the Inception V3 is then further trained using the output of the ST-network\n",
    "\n",
    "#### Load the weights of the trained Inception Architecture and train the SpatialTransformer. Update the weights of the final layer in the Inception V3. \n",
    "\n",
    "The resulting weights are saved, and are useable in the Evaluate notebook. The images will not be uploaded, and so this notebook is not runable. When training, images has been packaged in a .pickle file. The weights are saved in the Keras .HDF5 format. \n",
    "\n",
    "Authors:\n",
    "* s134859 Nicolai Mogensen\n",
    "* s134569 Tobias Slot Jensen\n",
    "* s144242 David Frich Hansen\n",
    "\n",
    "References:\n",
    "* SpatialTransformer Keras Implementation Hello2all: https://github.com/hello2all/GTSRB_Keras_STN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 299\n",
    "import numpy as np\n",
    "from label_image import *\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from PIL import Image,ImageOps\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.layers import (Activation, Dense, Dropout, Flatten,\n",
    "                          Lambda, MaxPooling2D)\n",
    "import performance_measures\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from spatial_transformer import SpatialTransformer\n",
    "from keras.applications import InceptionV3\n",
    "import pickle\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,LambdaCallback,Callback\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.special import expit\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the pickled data, this data is NOT uploaded as it is confidential\n",
    "with open('images.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference \"Hello2All\"\n",
    "def locnet():\n",
    "    num_weights = 6\n",
    "    b = np.zeros((2, 3), dtype='float32')\n",
    "    \n",
    "    # These parameters indicate zoom\n",
    "    # Initialize these to be less than one to avoid infinite zoom-out\n",
    "    b[0, 0] = 0.40\n",
    "    b[1, 1] = 0.40\n",
    "    \n",
    "    W = np.repeat(np.array([0.0,0.0,0.0,0.0,0.0,0.0],dtype='float32'),num_weights).reshape(num_weights,6,order=\"F\")\n",
    "    weights = [W, b.flatten()]\n",
    "    \n",
    "    locnet = Sequential()\n",
    "\n",
    "    locnet.add(Conv2D(16, (7, 7), padding='valid', input_shape=(299, 299, 3)))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    locnet.add(Conv2D(32, (5, 5), padding='valid'))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    locnet.add(Conv2D(64, (3, 3), padding='valid'))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    locnet.add(Flatten())\n",
    "    locnet.add(Dense(128))\n",
    "    locnet.add(Activation('relu'))\n",
    "    locnet.add(Dense(64))\n",
    "    locnet.add(Activation('relu'))\n",
    "    locnet.add(Dense(num_weights))\n",
    "    locnet.add(Activation('relu'))\n",
    "    locnet.add(Dense(6, weights=weights))\n",
    "\n",
    "    return locnet\n",
    "\n",
    "def conv_model(input_shape=(299, 299,3)):\n",
    "    \n",
    "    # Part that contains ST-net\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(\n",
    "        lambda x: x,\n",
    "        input_shape=input_shape,\n",
    "        output_shape=input_shape))\n",
    "    \n",
    "    # Batch normalize to \"relax\" the weights and avoid explosion\n",
    "    model.add(BatchNormalization())\n",
    "    stnet = SpatialTransformer(localization_net=locnet(),\n",
    "                                 output_size=(299,299)) #Resize to 299x299\n",
    "    \n",
    "    model.add(stnet)\n",
    "    \n",
    "    # Inception, load weights from HDF5 file, previously trained\n",
    "    model_2 = Sequential()\n",
    "    inc_v3 = InceptionV3(include_top=False, weights='imagenet', pooling='max',classes=2)\n",
    " \n",
    "    # Don't train the layers, as everything is already trained\n",
    "    for layer in inc_v3.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model_2.add(inc_v3)\n",
    "    #model_2.add(BatchNormalization())\n",
    "    output = Dense(2, activation='softmax')\n",
    "    # Lets keep training the final layer, to obtain end-to-end\n",
    "    output.trainable = True\n",
    "    \n",
    "    \n",
    "    model_2.add(output)\n",
    "    # Load the inception weights as obtained in another notebook\n",
    "    model_2.load_weights(\"inception_pure.hdf5\")\n",
    "   \n",
    "    # Add the Inception Conv Net after the ST-net\n",
    "    model.add(model_2)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30 # Previously this was 300 epochs, but the weights explodes after too many epochs\n",
    "model = conv_model()\n",
    "\n",
    "model.summary()\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Override Keras callback to plot transformed images after each epoch\n",
    "class PlotTestset(Callback):\n",
    "    # on_epoch_end is a keras function which we overwrite\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        y_prob = model.predict(data[\"X_test\"]) # Probabilities from Softmax\n",
    "        st_img = intermediate_layer_model.predict(data[\"X_test\"]) # Transformed images\n",
    "        y_pred = np.argmax(y_prob,axis=1) # Classification\n",
    "        \n",
    "        # subplot parameters\n",
    "        p1 = 1\n",
    "        p2 = 2\n",
    "        # Plot just the first 3 images\n",
    "        for i in range(3):\n",
    "            plt.figure(figsize = (12,12))\n",
    "            plt.subplot(10,2,p1)\n",
    "            # Normalize the images so we can plot them\n",
    "            tmp_img = st_img[i]+np.abs(np.amin(st_img[i]))\n",
    "            tmp_img = tmp_img/(np.amax(st_img[i])-np.amin(st_img[i]))\n",
    "            print(\"Shape of output:\",st_img[i].shape)\n",
    "            print(\"Shape of input:\",data[\"X_test\"].shape)\n",
    "            plt.imshow(tmp_img)\n",
    "            #plt.imshow(st_img[i])\n",
    "            \n",
    "            plt.axis('off')\n",
    "            plt.subplot(10,2,p2)\n",
    "            plt.imshow(data[\"X_test\"][i])\n",
    "            plt.axis('off')\n",
    "            \n",
    "            acne_pred = \"Vulgaris\"\n",
    "            acne_true = \"Vulgaris\"\n",
    "            if(y_pred[i] == 1):\n",
    "                acne_pred = \"Rosacea\"\n",
    "            if(data[\"y_test\"][i] == 1):\n",
    "                acne_true = \"Rosacea\"\n",
    "                \n",
    "            print(\"\\nPrediction: \" + str(y_pred[i]) + \" \" + acne_pred)\n",
    "            print(\"True: \" + str(data[\"y_test\"][i]) + \" \" + acne_true)\n",
    "            plt.show()\n",
    "            p1 += 2\n",
    "            p2 += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keras does validation splits for us, so combine the Training and Validation data, and let Keras split it. \n",
    "data[\"X_train_c\"] = np.concatenate((data[\"X_train\"],data[\"X_valid\"]),axis=0)\n",
    "data[\"y_train_c\"] = np.concatenate((data[\"y_train\"],data[\"y_valid\"]),axis=0)\n",
    "\n",
    "# Intermediate model that lets us take out the transformed image to plot.\n",
    "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer(\"spatial_transformer_1\").output)\n",
    "# checkpointer lets us save the weights at each epoch\n",
    "checkpointer = ModelCheckpoint(filepath=\"STnet.hdf5\", verbose=1, save_best_only=False, save_weights_only=True)\n",
    "# plot callback\n",
    "plottest = PlotTestset()\n",
    "\n",
    "# Train the model with the parameters\n",
    "try:\n",
    "    model.fit(data[\"X_train_c\"], data[\"y_train_c\"],\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=0.1,\n",
    "                shuffle=True,\n",
    "                callbacks=[plottest,checkpointer])\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    print(\"training interrupted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "score = model.evaluate(x=data[\"X_test\"], y=data[\"y_test\"])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from performance_measures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(data[\"X_test\"])\n",
    "y_pred = np.argmax(y_prob,axis=1)\n",
    "y_true = data[\"y_test\"]\n",
    "\n",
    "AUC = get_roc_auc(y_true,y_prob[:,1])\n",
    "accuracy = score[1]\n",
    "\n",
    "#True Negative Rate 0,0\n",
    "specificity = get_specificity(y_true,y_pred)\n",
    "#True Positive Rate 1,1\n",
    "sensitivity = get_sensitivity(y_true,y_pred)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Sensitivity:\",sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some images from the test set (Again, we can not show this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(data[\"X_test\"]) # Probabilities from Softmax\n",
    "st_img = intermediate_layer_model.predict(data[\"X_test\"]) # Transformed images\n",
    "y_pred = np.argmax(y_prob,axis=1) # Classification\n",
    "\n",
    "# subplot parameters\n",
    "p1 = 1\n",
    "p2 = 2\n",
    "# Plot just the first 3 images\n",
    "for i in range(3):\n",
    "    plt.figure(figsize = (12,12))\n",
    "    #plt.subplot(10,2,p1)\n",
    "    # Normalize the images so we can plot them\n",
    "    tmp_img = st_img[i]+np.abs(np.amin(st_img[i]))\n",
    "    tmp_img = tmp_img/(np.amax(st_img[i])-np.amin(st_img[i]))\n",
    "    #print(\"Shape of output:\",tmp_img[i].shape)\n",
    "    #print(\"Shape of st_img:\",st_img[i])\n",
    "    #print(\"Shape of input:\",data[\"X_test\"].shape)\n",
    "    \n",
    "    plt.imshow(tmp_img)\n",
    "    #plt.imshow(st_img[i])\n",
    "\n",
    "    plt.axis('off')\n",
    "    #plt.subplot(10,2,p2)\n",
    "    #plt.imshow(data[\"X_test\"][i])\n",
    "    #plt.axis('off')\n",
    "\n",
    "    acne_pred = \"Vulgaris\"\n",
    "    acne_true = \"Vulgaris\"\n",
    "    if(y_pred[i] == 1):\n",
    "        acne_pred = \"Rosacea\"\n",
    "    if(data[\"y_test\"][i] == 1):\n",
    "        acne_true = \"Rosacea\"\n",
    "\n",
    "    print(\"\\nPrediction: \" + str(y_pred[i]) + \" \" + acne_pred)\n",
    "    print(\"True: \" + str(data[\"y_test\"][i]) + \" \" + acne_true)\n",
    "    plt.show()\n",
    "    p1 += 2\n",
    "    p2 += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
