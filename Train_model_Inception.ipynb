{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02456 Deep Learning - Acne Vulgaris vs Acne Rosacea\n",
    "\n",
    "# Train last layer of Inception\n",
    "\n",
    "__Note__ the best performance was *not* obtained by this Keras implementation, but the Google implementation, which is linked in the references. In theory they should be the same, but the Keras implementation is not performing as good. In the report the google implementation is marked as the best performing model, and can be tested using the notebook \"Evaluate_model_retrain.ipynb\" which uses the best model (And therefore not this model). \n",
    "\n",
    "This notebook is just to show how to train a Keras implementation of the Inception V3 Model, if you want to evaluate some of your own images, use the Evaluate notebooks, which contains already trained networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Retrain last layer of Inception V3 - Using Keras\n",
    "\n",
    "Authors:\n",
    "* s134859 Nicolai Mogensen\n",
    "* s134569 Tobias Slot Jensen\n",
    "* s144242 David Frich Hansen\n",
    "\n",
    "References:\n",
    "* The Google Transfer Learning implementation: https://www.tensorflow.org/tutorials/image_retraining\n",
    "\n",
    "##### Network was trained using a GTX 1080 Ti. If you experience OOM errors, it is probably because the network does not fit into your memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/jupyterhub/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "DIM = 299\n",
    "import numpy as np\n",
    "from label_image import *\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from PIL import Image,ImageOps\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.layers import (Activation, Dense, Dropout, Flatten,\n",
    "                          Lambda, MaxPooling2D)\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from spatial_transformer import SpatialTransformer\n",
    "from keras.applications import InceptionV3\n",
    "import pickle\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,LambdaCallback,Callback\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.special import expit\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the pickled data, this data is NOT uploaded as it is confidential\n",
    "with open('images.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_model(input_shape=(299, 299,3)):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(\n",
    "        lambda x: x,\n",
    "        input_shape=input_shape,\n",
    "        output_shape=input_shape))\n",
    "    \n",
    "    inc_v3 = InceptionV3(include_top=False, weights='imagenet', pooling='max',classes=2)\n",
    " \n",
    "    # Don't train the layers, as everything is already trained\n",
    "    for layer in inc_v3.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.add(inc_v3)\n",
    "    output = Dense(2, activation='softmax')\n",
    "    \n",
    "    model.add(output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "model = conv_model()\n",
    "\n",
    "model.summary()\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1026 samples, validate on 114 samples\n",
      "Epoch 1/100\n",
      "1026/1026 [==============================] - 6s - loss: 1.6729 - acc: 0.4990 - val_loss: 1.4211 - val_acc: 0.4123\n",
      "Epoch 2/100\n",
      "1026/1026 [==============================] - 5s - loss: 1.2547 - acc: 0.5478 - val_loss: 1.3931 - val_acc: 0.4474\n",
      "Epoch 3/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.9403 - acc: 0.6023 - val_loss: 1.5134 - val_acc: 0.5175\n",
      "Epoch 4/100\n",
      "1026/1026 [==============================] - 5s - loss: 1.0253 - acc: 0.6179 - val_loss: 0.9267 - val_acc: 0.6053\n",
      "Epoch 5/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.7187 - acc: 0.6881 - val_loss: 0.8128 - val_acc: 0.6404\n",
      "Epoch 6/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.7162 - acc: 0.6852 - val_loss: 0.8364 - val_acc: 0.6491\n",
      "Epoch 7/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.6715 - acc: 0.6998 - val_loss: 0.7538 - val_acc: 0.6754\n",
      "Epoch 8/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.6427 - acc: 0.7125 - val_loss: 0.6322 - val_acc: 0.7807\n",
      "Epoch 9/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.6233 - acc: 0.7271 - val_loss: 0.6420 - val_acc: 0.7368\n",
      "Epoch 10/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.6680 - acc: 0.7066 - val_loss: 0.7775 - val_acc: 0.6842\n",
      "Epoch 11/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5893 - acc: 0.7476 - val_loss: 0.5970 - val_acc: 0.7544\n",
      "Epoch 12/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5662 - acc: 0.7417 - val_loss: 0.6129 - val_acc: 0.7632\n",
      "Epoch 13/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5622 - acc: 0.7671 - val_loss: 0.5759 - val_acc: 0.7632\n",
      "Epoch 14/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5203 - acc: 0.7680 - val_loss: 0.5927 - val_acc: 0.7544\n",
      "Epoch 15/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5033 - acc: 0.7865 - val_loss: 0.5942 - val_acc: 0.7456\n",
      "Epoch 16/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5175 - acc: 0.7758 - val_loss: 0.5748 - val_acc: 0.7807\n",
      "Epoch 17/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5597 - acc: 0.7739 - val_loss: 0.6466 - val_acc: 0.7632\n",
      "Epoch 18/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4765 - acc: 0.7846 - val_loss: 0.6725 - val_acc: 0.7456\n",
      "Epoch 19/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5078 - acc: 0.7661 - val_loss: 0.6726 - val_acc: 0.7632\n",
      "Epoch 20/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5771 - acc: 0.7690 - val_loss: 0.5933 - val_acc: 0.7544\n",
      "Epoch 21/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4606 - acc: 0.7875 - val_loss: 0.6045 - val_acc: 0.7368\n",
      "Epoch 22/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5542 - acc: 0.7554 - val_loss: 0.5721 - val_acc: 0.7632\n",
      "Epoch 23/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.5328 - acc: 0.7739 - val_loss: 0.5425 - val_acc: 0.7807\n",
      "Epoch 24/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4418 - acc: 0.7992 - val_loss: 0.5448 - val_acc: 0.7719\n",
      "Epoch 25/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4183 - acc: 0.8051 - val_loss: 0.5397 - val_acc: 0.7982\n",
      "Epoch 26/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4667 - acc: 0.8051 - val_loss: 0.5380 - val_acc: 0.7982\n",
      "Epoch 27/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4398 - acc: 0.8080 - val_loss: 0.5439 - val_acc: 0.7719\n",
      "Epoch 28/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4524 - acc: 0.8099 - val_loss: 0.5641 - val_acc: 0.7632\n",
      "Epoch 29/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4859 - acc: 0.7895 - val_loss: 0.5789 - val_acc: 0.7456\n",
      "Epoch 30/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4114 - acc: 0.8109 - val_loss: 0.5471 - val_acc: 0.7632\n",
      "Epoch 31/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4271 - acc: 0.8129 - val_loss: 0.5493 - val_acc: 0.7632\n",
      "Epoch 32/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4373 - acc: 0.8119 - val_loss: 0.6602 - val_acc: 0.7456\n",
      "Epoch 33/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4334 - acc: 0.8216 - val_loss: 0.5457 - val_acc: 0.7807\n",
      "Epoch 34/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3987 - acc: 0.8236 - val_loss: 0.5498 - val_acc: 0.7807\n",
      "Epoch 35/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4282 - acc: 0.8119 - val_loss: 0.5582 - val_acc: 0.7544\n",
      "Epoch 36/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4191 - acc: 0.8197 - val_loss: 0.5472 - val_acc: 0.7632\n",
      "Epoch 37/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3922 - acc: 0.8324 - val_loss: 0.5581 - val_acc: 0.7544\n",
      "Epoch 38/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4186 - acc: 0.8168 - val_loss: 0.5639 - val_acc: 0.7632\n",
      "Epoch 39/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3841 - acc: 0.8314 - val_loss: 0.5475 - val_acc: 0.7807\n",
      "Epoch 40/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3861 - acc: 0.8343 - val_loss: 0.5663 - val_acc: 0.7632\n",
      "Epoch 41/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4014 - acc: 0.8255 - val_loss: 0.5374 - val_acc: 0.7895\n",
      "Epoch 42/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4162 - acc: 0.8158 - val_loss: 0.5659 - val_acc: 0.7544\n",
      "Epoch 43/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4035 - acc: 0.8314 - val_loss: 0.5399 - val_acc: 0.7895\n",
      "Epoch 44/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3957 - acc: 0.8275 - val_loss: 0.5440 - val_acc: 0.7807\n",
      "Epoch 45/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3821 - acc: 0.8255 - val_loss: 0.5468 - val_acc: 0.7807\n",
      "Epoch 46/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3850 - acc: 0.8304 - val_loss: 0.5420 - val_acc: 0.7807\n",
      "Epoch 47/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3666 - acc: 0.8431 - val_loss: 0.5501 - val_acc: 0.7719\n",
      "Epoch 48/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4153 - acc: 0.8207 - val_loss: 0.5491 - val_acc: 0.7807\n",
      "Epoch 49/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3914 - acc: 0.8285 - val_loss: 0.5450 - val_acc: 0.7719\n",
      "Epoch 50/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3787 - acc: 0.8421 - val_loss: 0.5796 - val_acc: 0.7632\n",
      "Epoch 51/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3738 - acc: 0.8431 - val_loss: 0.5588 - val_acc: 0.7719\n",
      "Epoch 52/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3681 - acc: 0.8431 - val_loss: 0.5319 - val_acc: 0.7982\n",
      "Epoch 53/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3678 - acc: 0.8431 - val_loss: 0.5309 - val_acc: 0.7719\n",
      "Epoch 54/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3685 - acc: 0.8509 - val_loss: 0.5327 - val_acc: 0.7807\n",
      "Epoch 55/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3838 - acc: 0.8470 - val_loss: 0.5351 - val_acc: 0.7807\n",
      "Epoch 56/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3471 - acc: 0.8441 - val_loss: 0.5271 - val_acc: 0.7807\n",
      "Epoch 57/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3464 - acc: 0.8441 - val_loss: 0.5300 - val_acc: 0.7895\n",
      "Epoch 58/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4097 - acc: 0.8226 - val_loss: 0.5249 - val_acc: 0.7632\n",
      "Epoch 59/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.4256 - acc: 0.8187 - val_loss: 0.5486 - val_acc: 0.7719\n",
      "Epoch 60/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3677 - acc: 0.8470 - val_loss: 0.5213 - val_acc: 0.7807\n",
      "Epoch 61/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3707 - acc: 0.8441 - val_loss: 0.5229 - val_acc: 0.7719\n",
      "Epoch 62/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3315 - acc: 0.8587 - val_loss: 0.5159 - val_acc: 0.7807\n",
      "Epoch 63/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3529 - acc: 0.8450 - val_loss: 0.5275 - val_acc: 0.7895\n",
      "Epoch 64/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3604 - acc: 0.8460 - val_loss: 0.5368 - val_acc: 0.7632\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026/1026 [==============================] - 5s - loss: 0.3818 - acc: 0.8333 - val_loss: 0.5247 - val_acc: 0.7719\n",
      "Epoch 66/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3464 - acc: 0.8499 - val_loss: 0.5172 - val_acc: 0.7719\n",
      "Epoch 67/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3637 - acc: 0.8441 - val_loss: 0.5291 - val_acc: 0.7895\n",
      "Epoch 68/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3962 - acc: 0.8324 - val_loss: 0.5550 - val_acc: 0.7632\n",
      "Epoch 69/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3887 - acc: 0.8265 - val_loss: 0.5440 - val_acc: 0.7632\n",
      "Epoch 70/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3477 - acc: 0.8489 - val_loss: 0.5275 - val_acc: 0.7632\n",
      "Epoch 71/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3223 - acc: 0.8626 - val_loss: 0.5276 - val_acc: 0.7807\n",
      "Epoch 72/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3565 - acc: 0.8577 - val_loss: 0.5298 - val_acc: 0.7456\n",
      "Epoch 73/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3336 - acc: 0.8665 - val_loss: 0.5209 - val_acc: 0.7807\n",
      "Epoch 74/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3290 - acc: 0.8567 - val_loss: 0.5229 - val_acc: 0.7544\n",
      "Epoch 75/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3585 - acc: 0.8382 - val_loss: 0.5190 - val_acc: 0.7807\n",
      "Epoch 76/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3414 - acc: 0.8363 - val_loss: 0.5261 - val_acc: 0.7544\n",
      "Epoch 77/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3399 - acc: 0.8431 - val_loss: 0.5122 - val_acc: 0.7895\n",
      "Epoch 78/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3316 - acc: 0.8587 - val_loss: 0.5098 - val_acc: 0.7895\n",
      "Epoch 79/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3757 - acc: 0.8353 - val_loss: 0.5247 - val_acc: 0.7632\n",
      "Epoch 80/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3525 - acc: 0.8450 - val_loss: 0.5159 - val_acc: 0.7982\n",
      "Epoch 81/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3340 - acc: 0.8548 - val_loss: 0.5173 - val_acc: 0.7544\n",
      "Epoch 82/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3375 - acc: 0.8616 - val_loss: 0.5135 - val_acc: 0.7895\n",
      "Epoch 83/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3224 - acc: 0.8626 - val_loss: 0.5151 - val_acc: 0.7719\n",
      "Epoch 84/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3124 - acc: 0.8665 - val_loss: 0.5139 - val_acc: 0.7895\n",
      "Epoch 85/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3393 - acc: 0.8460 - val_loss: 0.5112 - val_acc: 0.7807\n",
      "Epoch 86/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3317 - acc: 0.8548 - val_loss: 0.5134 - val_acc: 0.7807\n",
      "Epoch 87/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3126 - acc: 0.8665 - val_loss: 0.5257 - val_acc: 0.7719\n",
      "Epoch 88/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3707 - acc: 0.8265 - val_loss: 0.5105 - val_acc: 0.7807\n",
      "Epoch 89/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3545 - acc: 0.8548 - val_loss: 0.5095 - val_acc: 0.7719\n",
      "Epoch 90/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3220 - acc: 0.8519 - val_loss: 0.5098 - val_acc: 0.7719\n",
      "Epoch 91/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3205 - acc: 0.8626 - val_loss: 0.5222 - val_acc: 0.7632\n",
      "Epoch 92/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3452 - acc: 0.8441 - val_loss: 0.5112 - val_acc: 0.7807\n",
      "Epoch 93/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3188 - acc: 0.8626 - val_loss: 0.5124 - val_acc: 0.7632\n",
      "Epoch 94/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3219 - acc: 0.8528 - val_loss: 0.5167 - val_acc: 0.7982\n",
      "Epoch 95/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3484 - acc: 0.8441 - val_loss: 0.5120 - val_acc: 0.7632\n",
      "Epoch 96/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3460 - acc: 0.8402 - val_loss: 0.5118 - val_acc: 0.7895\n",
      "Epoch 97/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3571 - acc: 0.8450 - val_loss: 0.5149 - val_acc: 0.7719\n",
      "Epoch 98/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3670 - acc: 0.8382 - val_loss: 0.5105 - val_acc: 0.7807\n",
      "Epoch 99/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3094 - acc: 0.8752 - val_loss: 0.5096 - val_acc: 0.7982\n",
      "Epoch 100/100\n",
      "1026/1026 [==============================] - 5s - loss: 0.3139 - acc: 0.8743 - val_loss: 0.5113 - val_acc: 0.7719\n"
     ]
    }
   ],
   "source": [
    "# Keras does validation splits for us, so combine the Training and Validation data, and let Keras split it. \n",
    "data[\"X_train_c\"] = np.concatenate((data[\"X_train\"],data[\"X_valid\"]),axis=0)\n",
    "data[\"y_train_c\"] = np.concatenate((data[\"y_train\"],data[\"y_valid\"]),axis=0)\n",
    "\n",
    "try:\n",
    "    model.fit(data[\"X_train_c\"], data[\"y_train_c\"],\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=0.1,\n",
    "                shuffle=True,\n",
    "                callbacks=[])\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    print(\"training interrupted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s     \n",
      "[0.50668757756551108, 0.75000000794728594]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "score = model.evaluate(x=data[\"X_test\"], y=data[\"y_test\"])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde7464fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750000007947\n",
      "Specificity: 0.774193548387\n",
      "Sensitivity: 0.724137931034\n"
     ]
    }
   ],
   "source": [
    "from performance_measures import *\n",
    "\n",
    "y_prob = model.predict(data[\"X_test\"])\n",
    "y_pred = np.argmax(y_prob,axis=1)\n",
    "y_true = data[\"y_test\"]\n",
    "\n",
    "AUC = get_roc_auc(y_true,y_prob[:,1])\n",
    "accuracy = score[1]\n",
    "\n",
    "#True Negative Rate 0,0\n",
    "specificity = get_specificity(y_true,y_pred)\n",
    "#True Positive Rate 1,1\n",
    "sensitivity = get_sensitivity(y_true,y_pred)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Specificity:\",specificity)\n",
    "print(\"Sensitivity:\",sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('inckeras.h5') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
